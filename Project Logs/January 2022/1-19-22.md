# Overview of today: 
## What I did:  
Trained & tested larger sized models. Since they use more layers, training was slower and train-time batch size/image size also took a hit to fit memory requirements.
- YOLOv5MED took about 6 hours on batch size 8 img size 2000, and YOLOv5L and YOLOv5l6 took 7 on batch size 8 img size 1600. L6 had to be done on default train params (1280-8).
- Medium and large didn't show much improvement (either same LB or lower). Training time increased, F2 also increased but only a little bit, so not really worth it since I don't have 32GB.
    - This was likely due to the fact that I had to decrease the image size and batch size to train properly.
    - Inference time seems to be a bit longer, too. YOLOv5-l6 timed out, but not YOLOv5l(bit smaller than L-6). Weights are too large to publish (over 400MB).
    - One thing they did do better on was CV. Scores were around 0.75 despite LB being similar, with no CV leakage being detected.
Also continued tweaking model params. Likely overfit, but best possible public LB was 0.628 with image size 9500, row confidence 0.28, and model confidence 0.05.
- This lands me in the upper 30s. Highest I've ever been, this is a miracle! I still want to hit that sweet .675 that marks off the top 10, though. The dream is 0.7!
## What I now know:
- Larger sized models work better, but run slower and require more space to train. Therefore, it is not very feasible **for me** to go any higher than YOLOv5m.
    - I still have to keep in mind the optimal train size params, after all.
## Whatâ€™s next on the list:
- Continue working on that YOLO-Z model. This could be something promising!
    - All I have left is swapping with a DenseNet and using the XS feature maps.
- Read up on source code for YOLO.
    - Determine how to split and cross-validate. (more specifically, by sequence, video, or some other metric)
    - Implement any augmentation techniques. (any custom/predefined augmentations I can use to improve P/R in training?)
    - Check if temporal tracking can help.  (multi- or single object temporal tracking?)
    - Test-time augmentations/preprocessing may help as well (put simply, any postprocessing I can do?)
## Interesting tidbits/thoughts:
- Off topic but related to the contest: I've been seeing huge teams be the top rankers so far on this contest(like 5+ members, the heck?). 
    - When did novices team up with kaggle masters? Also, isn't that bad for learning if you just get carried by experienced people?
- Larger models seem to work at the same resolution. Larger model+smaller res/batch size is still not better than baseline+optimal train size. 
    - Perhaps this may be a GPU race, but good post processing techniques also play a huge role. 
    - What's obvious is what mostly everyone with hardware will do, so being smart with inferencing could help me stay ahead of the race.
- I could try inpainting COTS into the dataset, like pull some off the internet and blend them into another fake dataset? Could synergize well with transfer learning?
- I doubt transfer learning from wide->small would work. The difference in file sizes+number of weights is too obvious, and would probably not train well, if could at all.
