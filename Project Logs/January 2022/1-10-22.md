# Overview of today: 
## What I did:  
Finished up writing the test inference harness. Pretty simple, just a couple of imports, load model, and infer on finished data.  
I say that, but it was still pretty tough to figure out what exactly to predict, haha... We'll know our results by tomorrow!
- This was tough to figure out, I spent a day with a .pt file, not knowing how to even load it. Kinda sad, but I was making way too much progress with way too little resistance, heh.
- Inference seems good on the images, but I can't really tell since the first 3 frames at least have no COTS and my model seems fine on that end, at least.
    - Based on how the contest is structured, I can only run through the notebook once per session, since the environment uses an iterator to predict images.
    - This means I gotta restart the kernel session each time I want to infer, which may get cumbersome later on. 
## What I now know:
- How to infer on a Pytorch-implemented YOLO model. Possibly scales to other models as well, so long as they posess Pytorch mirrors and complete GitHub repos.
## Whatâ€™s next on the list:
- Read up on code documentation for the models mentioned above (SWIN, DETR, etc.).
    - See if training parameters or even the model architectures themselves can be tweaked.
    - Determine how to split and cross-validate.
    - Try to see if I can view the predictions in image format. Like on train images, show the actual bounding boxes overlaid onto the train image, and compare what's going on.
## Interesting tidbits/thoughts:
- I wonder if any test-time inferencing aids exist? Probably not, as that wouldn't be really indicative of real-world data, right?
- This took a while to understand, but ultimately writing the code wasn't terrible.
## Data/Resources
- N/A
