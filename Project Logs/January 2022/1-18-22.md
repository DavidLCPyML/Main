# Overview of today: 
## What I did:  
Tested several models against current baseline, trained off of different theories that I thought would work.
- Theory 1: A larger batch size will help model accuracy even if image size is decreased.
    - Rationale: Since the original baseline trained off a batch size of 4 and nearly takes up all the VRAM in a P100, 
    perhaps downsizing the image size but increasing batch size will help improve convergence and accuracy-related metrics. 
    This is because YOLOv5 uses batch normalization, which has proven to be in most cases very affective at producing improvements.
    - Didn't show much improvement, scoring 0.529 on the same parameters. 
    - A second model trained on 2x the previous batch size and 1600 image resolution performed around the same, at a score of 0.521.
    - Theory 1 was disproved, meaning that the higher the image resolution the better, but perhaps transfer learning could be used to finetune the model backbone.
    - A third model timed out, possibly due to lack of GPU acceleration on inference.
    - However, increased batch size does help with convergence and F2 a tiny bit, as a batch size of 2x is still better than a batch size of x.
    - Conclusion: The native resolution must not be the same resolution as the provided image, as a higher resolution yields better results.
          - This should not normally be the case, since an image blown up to 3x the original size will still encode the same features unless it's been downsized and resized.
- Continued playing around with hyperparams, modifying model confidence and row confidence a bit more. No improvement on that end, still scores 0.627 on public LB.
    - Will still keep trying, need a couple more experiments to confirm.
- Saw a norfair library floating around somewhere, may check that later and see how it works.
    - Seems to me like that one works the best, haven't seen any other trackers being used. 
    - If I recall correctly, they increase FP but are more consistent with guesses temporally. So a model would beenfit if it has low FP but a tendency to break its stream of focus.
## What I now know:
- For this imaging challenge, a higher resolution in training (around 3000-4000) should be an ideal train size. Batch size should still be the larger the better.
- Other improvements to LB would likely be from test time, simply increasing inference res won't work for most models.
## Whatâ€™s next on the list:
- Read up on source code for YOLO.
    - Try a larger model. Maybe I'd get better results with a scaled up model (more features/boxes to use?)
    - Determine how to split and cross-validate. (more specifically, by sequence, video, or some other metric)
    - Implement any augmentation techniques. (any custom/predefined augmentations I can use to improve P/R in training?)
    - Check if temporal tracking can help.  (multi- or single object temporal tracking?)
    - Test-time augmentations/preprocessing may help as well (put simply, any postprocessing I can do?)
- See if I can implement a proper/similar YOLO-Z model.
    - If successful, compare results with a proper YOLO result. How will it look? Will it generalize?
## Interesting tidbits/thoughts:
- Higher res is a possible train optimizer. 
    - The native resolution is likely higher than the one in the train set, otherwise there wouldn't be such a large improvement just with this highres trick.
    - This may devolve into a GPU horse race, but it's unlikely since experimenting with a img size of 4k+ seems to not have any improvement, according to some people on Kaggle.
    - I think one guy theorized that the native resolution was something like 3800x2168? Either way, native res is approx 3x the resolution of the data in the train set.
- I could try inpainting COTS into the dataset, like pull some off the internet and blend them into another fake dataset? Could synergize well with transfer learning?
- From what I've seen, transfer learning may possibly work. However, I'm not sure if training from low->high or high->low res works best for improving model metrics.
