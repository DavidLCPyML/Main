# Overview of today: 
## What I did:  
Explored the Tensorflow Great Barrier Reef challenge. Prizes of up to 50k$, chance for real-world implementation. Not much of a chance here, but let's give it a shot.
- So, this is an object detection/Computer Vision challenge. So, ConvNets or transformer augmentation, right?
- 1280x768 are the input dimensions. Hmm... that's MUCH larger than any image I've tried recently...
- Supposedly I'm supposed to identify any size Crown-of-Thorns starfish (COTS) that appear in experimental videos, in or as close to near-real time as possible.
- Accepted the rules right after Christmas 2021, but didn't do any thorough looking until now.
    - Looks like the videos are split into frames, but they're not ordered chronologically (for example, frame 1000 is after frame 100 in the train image directory).
    - Current leaderboard seems to be struggling to break 0.6, at least for the public set, which I assume is probably like a half of a video or something similar.
- 23501 total images, with 6 columns, representing video id, sequence #, video frame, sequence frame, image id, and the actual COTS annotations.
    - It does look like there aren't many frames with COTS in them, despite there being no shortage of actual COTS objects themselves.
    - I need to predict both the presence of an object, as well as the coordinates of the smallest box encompassing it. Looks like the model needs to be a lot deeper then.
- I'll probably have to use one of the SoTA models, like YOLO or swin-T/DETR, as it's no use building one from scratch since that would take too much time.
    - I'll have to learn how to implement/"load" these models in my programs, it seems. Let's see which one works, yea?
## What I now know:
- Right now trying to make sense of the dataset.
- a video frame will have a blank array if there are no COTS. If they do exist, it will be output in an array in the same format as likely YOLO/COCO format
    - Annotations consist of an x and y offset of a corner value, a width, and a height. 
    - Based on these, it's likely COCO format.
- The competition metric is F2 loss, not F1, so that should mean more FPs are allowed compared to FN.
- No test set needed, so I'll have to figure out a validation split.
## Whatâ€™s next on the list:
- Read up on code documentation for the models mentioned above (SWIN, DETR, YOLO, etc.).
    - Find a way to load them in a notebook for training. 
    - See if training parameters or even the model architectures themselves can be tweaked.
    - Train up some models, and test them out.
    - Determine how and what to cross-validate.
    - Figure out how to port finished models for inferencing. I don't want to have to retrain each time I submit, since that would be too tragic and a waste of my GPU time.
## Interesting tidbits/thoughts:
- I only have 9 hours to train a model (Colab/Kaggle notebook imposed limits), so I'll have to figure out both efficiency and accuracy.
- Many models weight with F1, so I think I have to change the way they evaluate this metric (to F2).
- I wonder if GANs can be used to augment this data. Not many images have COTS in them , based off of a quick analysis of csv spreadsheet data.
- Would R-CNNs work? I know they're, like, really slow, but they ARE pretty accurate for their age.
## Data/Resources
- https://www.kaggle.com/c/tensorflow-great-barrier-reef/overview/description: The contest itself
- https://arxiv.org/abs/2111.14311: link to the paper that published the dataset
