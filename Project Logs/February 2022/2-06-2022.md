# Overview of today: 
## What I did:  
Attempted a finetune-transfer learning model. Insight gained from https://www.kaggle.com/c/tensorflow-great-barrier-reef/discussion/304725
- Storage space was a problem, so I ended up having to cut down and transfer at multiple checkpoints.
      - about 2-3 training transfers at 3000/4 on a s6 model was enough to resemble the poster's model results. However, larger batch size would be optimal.
      - Modified some code to report F2 metric rather than F1 metric, didn't seem to work the first couple of times but got it eventually.
      - Followed instructions from https://www.kaggle.com/bamps53/competition-metric-implementation and from https://www.kaggle.com/c/tensorflow-great-barrier-reef/discussion/302241
      - did sequence fold split. Subsequences causes a small amount of leakage, and I needed something that accurately reflected the experimental results.
- For the finetune, needed to cut down again. More transfer learning, freeze the backbone and only tune the other layers.
      - To be honest, though, this model doesn't feel right - it feels like I made this with a lot of guesswork and gut instinct.
      - Half expected this to fail horribly, was very surprised when it beat personal best (0.66, still good but not comparable to the original author's model).
      - Optimal size was around 6000, not like the 9000 res the earlier model needed. Still suspiciously high res but less so.
- Scrapped this model - don't have a good feeling on its performance with the private set despite having promising baseline results.
Attempted to do a lot of things - Albumentations, sequential finetunes (downsampling & upsampling), ensembles w/ various smoothing algorithms, and F2 evaluations on each model's results
- Albumentations is kinda like the YOLO default, except you can make your own custom set.
      - Used blur & downscale, sharpening/noise compression, and brightness contrast. Didn't see many noticeable results here (scores were around 0.56)
      - Maybe they're not strong enough? Do these play a role at all?
- Sequential downsampling doesn't work if you go too low.
      - Downsampled 3 times model went from .665(used the author's model) to .601. Scrapped technique since native res is probably not 1280.
      - I assume it's because I had too many passes through the train set, causing it to overfit.
      - Curiously, upsampling kept throwing out of memory exceptions when I tried to implement it.
- Ensembles: I tested NMS, seq-NMS, WBF, and NMW smoothing.
      - They all looked kind of the same, so it took a while to find actual differences. 
      - Maybe it was because so many of my models were structurally the same, I didn't see much difference?
      - WBF seemed to have a bit less FPs than the rest, so I went with that. 
      - Didn't do so hot here, score of 0.609 and 0.632 at native and optimal LB resolutions, respectively.
      - Tried adding a tracking modeule, but it didn't work out due to submission conflicts.  
- F2 evaluation: Ran validation test passes through each model to see if I could get any insights on prediction confidence.
      - Found that some promising models with less than 100 FNs on the validation did very poorly on the test set. Presumably because of overfitting.
      - Did the same with norfair tracking, got some weird results and I don't know how to interpret it.
## What I now know:
I can't prove these until my private test set scores are released. Purely speculation right now.
- I assume the finetune works as well as it does because it uses the header to identify areas of interest on high res.
- Then the other layers focus in on the prominent features with smaller res?
## Whatâ€™s next on the list:
- Try to implement any last-minute inference or Test time augmentation techniques.
- Try that CLAHE enhancement technique.
- Try the HSV(Hue Saturation) augmentation.
- See if postprocessing will work.
## Data/Resources:
- https://www.kaggle.com/c/tensorflow-great-barrier-reef/discussion/304725: Discussion that I tried reproducing results from
- https://www.kaggle.com/alexchwong/yolov5-training-with-albumentations: Albumentations implementation template I followed
- https://www.kaggle.com/c/tensorflow-great-barrier-reef/discussion/302241: guide I found that walks through F2 contest implementation
